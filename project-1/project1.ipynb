{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "we will start with Data Collection first from Kaggle and as we have imported the required Data we shall then move on to EDA\n",
    "\n",
    "During EDA(Exploratory Data Analytics) and this is a neccessary step towards a Machine Learning project since it helps with understanding the data and analyzing what models can be used to work on the data.\n",
    "\n",
    "Then we move on to Data PreProcessing where we perform under sampling and over sampling.\n",
    "\n",
    "Train Test Split - here we train and test the data\n",
    "Then work with tree Models like random forest, xtree boost classifier, etc. as well as use cross validation.\n",
    "\n",
    "Find the best trained model\n",
    "Then send unknown data and predict of our required goal i.e to find out if a customer will be leaving or not.\n",
    "\n",
    "Then we study the dataset and analyze what are the columns shown in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we download the required pytohn libraries for the prediction project\n",
    " do this by running these commands individually\n",
    "NOTE: run each command only after the previous has stopped running.\n",
    "Commands:\n",
    "\n",
    "pip install pandas \\n\n",
    "\n",
    "pip install numpy \n",
    "\n",
    "pip install scikit-learn\n",
    "\n",
    "pip install matplotlib \n",
    "\n",
    "pip install xgboost\n",
    "after this restart the python  kernel being used in the notebook.>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.oversampling import SMOTE #for oversampling technique to build a uniformly distributed target class\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split #from splitting data into train test and split\n",
    "\n",
    "# lets import few decision tree based models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from xgboost) (2.2.4)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from xgboost) (1.15.2)\n",
      "Downloading xgboost-3.0.0-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/253.9 MB\u001b[0m \u001b[31m520.9 kB/s\u001b[0m eta \u001b[36m0:05:54\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
